# Tennis Match Prediction Pipeline (v4)

This directory contains the v4 version of the tennis match prediction pipeline, which provides real-time predictions for upcoming tennis matches using historical match data and machine learning.

## Pipeline Overview

The v4 pipeline consists of several components:

1. **Data Collection** (`collect_future_matches.py`)
   - Fetches upcoming matches for the next 7 days
   - Creates/updates necessary database tables
   - Stores match information in `scheduled_matches` table

2. **Completed Match Update** (`update_completed_matches.py`)
   - Identifies scheduled matches that have been completed
   - Fetches match results from the matches table
   - Marks matches as processed in `scheduled_matches` table

3. **Historical Feature Generation** (`generate_historical_features.py`)
   - Processes new historical match data incrementally
   - Updates features for matches affected by rolling window calculations
   - Maintains `match_features` table for completed matches with `is_future=false`
   - Uses batch processing to handle large volumes efficiently
   - Supports time-based filtering to process only matches from a specified time period (e.g., last year, last 2 years)
   - Configurable via the `YEARS_TO_PROCESS` variable at the top of the file

4. **Future Feature Generation** (`generate_future_features.py`)
   - Generates features for upcoming matches
   - Uses historical data to calculate player statistics
   - Stores features in `match_features` table with `is_future=true`

5. **Model Training** (`train_model_v4.py`)
   - Trains XGBoost model on historical match data
   - Performs hyperparameter optimization
   - Generates performance metrics and visualizations
   - Saves model and metadata in `models/` directory

6. **Match Prediction** (`predict_matches.py`)
   - Loads latest trained model
   - Makes predictions for upcoming matches
   - Stores predictions in `match_predictions` table
   - Updates prediction accuracy as results come in

7. **Pipeline Orchestration** (`update_predictions.py`)
   - Coordinates the entire prediction pipeline
   - Can be run via cron job for automated updates
   - Handles logging and error reporting

## Match ID Handling

Understanding match ID relationships is crucial for working with this codebase:

1. **matches table**:
   - `id`: Auto-incremented primary key generated by the database
   - `match_num`: The external API's match ID (integer)

2. **scheduled_matches table**:
   - `match_id`: The external API's match ID (stored as string)
   - `is_processed`: Flag to mark matches as completed and processed

3. **match_features table**:
   - For historical matches: `match_id` refers to `matches.id` (auto-incremented PK)
   - For future matches: `match_id` refers to `scheduled_matches.match_id` (external API ID)
   - `is_future`: Flag to distinguish between historical and future matches
     - When a future match is completed, this flag is automatically updated to FALSE

4. **match_predictions table**:
   - `match_id`: References `scheduled_matches.match_id` (external API ID)

When joining tables, be careful to use the appropriate ID fields:
- To join `scheduled_matches` to `matches`: `scheduled_matches.match_id::integer = matches.match_num`
- For future matches in `match_features`: `match_features.match_id = scheduled_matches.match_id`
- For historical matches in `match_features`: `match_features.match_id = matches.id`

## Directory Structure

```
predictor/v4/
├── README.md                      # This file
├── collect_future_matches.py      # Data collection script
├── update_completed_matches.py    # Completed match update script
├── generate_historical_features.py # Historical feature generation
├── generate_future_features.py    # Future feature generation script
├── train_model_v4.py              # Model training script
├── predict_matches.py             # Prediction script
├── update_predictions.py          # Pipeline orchestration
├── models/                        # Trained models and metadata
│   ├── model_v4_*.json           # Model files
│   ├── features_v4_*.json        # Feature lists
│   └── metrics_v4_*.json         # Performance metrics
└── output/                        # Logs and visualizations
    ├── plots/                     # Performance plots
    └── *.log                      # Log files
```

## Database Tables

The pipeline uses the following tables:

1. `matches` - Historical match data
2. `match_features` - Match features for both historical and future matches
3. `scheduled_matches` - Upcoming match information
4. `match_predictions` - Match predictions and accuracy tracking

## Usage Guide

### Initial Setup

1. Ensure database connection is configured in `.env`:
```
DATABASE_URL=postgresql://user:password@host:port/dbname
TENNIS_API_KEY=your_api_key
```

2. Install required packages:
```bash
pip install -r requirements.txt
```

### Data Management

1. **Historical Data Collection**
   - Run `get_data_from_external_api.py` to populate historical match data:
   ```bash
   python external-api/get_data_from_external_api.py
   ```
   - Recommended frequency: Weekly (to capture completed match results)

2. **Elo Rating Calculation**
   - Run `calculate_elo.py` after collecting historical data to update Elo ratings:
   ```bash
   python database/calculate_elo.py
   ```
   - Ensures Elo columns in the matches table are populated

3. **Historical Feature Generation**
   - Run `generate_historical_features.py` to update features for new historical matches:
   ```bash
   python predictor/v4/generate_historical_features.py
   ```
   - Automatically included in the daily pipeline
   - Processes matches in batches to handle large volumes
   - Updates rolling window statistics for affected players
   - Supports time-based filtering via the `YEARS_TO_PROCESS` variable:
     - Set to `None` to process all matches (default)
     - Set to a number (e.g., `1`, `2`) to process only matches from the last X years
     - Useful for incremental updates or focusing on recent data

4. **Future Match Collection and Update**
   - Automatically handled by the pipeline
   - Updates daily when running `update_predictions.py`
   - Seamlessly transfers completed matches from scheduled to historical tables

### Model Training

1. **Training New Models**
   ```bash
   python predictor/v4/train_model_v4.py
   ```
   - Recommended frequency: Monthly
   - Reasons to train new model:
     - Significant new match data available
     - Performance degradation
     - Seasonal transitions

2. **Model Evaluation**
   - Check `output/plots/` for performance visualizations
   - Review metrics in `models/metrics_v4_*.json`

### Making Predictions

1. **Manual Update**
   ```bash
   python predictor/v4/update_predictions.py
   ```

2. **Automated Updates**
   Add to crontab:
   ```bash
   0 0 * * * cd /path/to/project && python predictor/v4/update_predictions.py
   ```

### Recommended Schedule

1. **Daily Operations** (via cron)
   - Run `update_predictions.py`
     - Collects upcoming matches
     - Updates completed matches
     - Updates historical match features
     - Generates future match features
     - Makes predictions
     - Updates accuracy

2. **Weekly Operations** (manual/scheduled)
   - Run `get_data_from_external_api.py`
     - Updates historical match data
     - Captures match results
     - Updates player statistics
   - Run `calculate_elo.py` 
     - Updates Elo ratings for new historical matches

3. **Monthly Operations** (manual)
   - Train new model
   - Review performance metrics
   - Adjust features if needed

4. **Quarterly Operations** (manual)
   - Full pipeline review
   - Feature engineering assessment
   - Historical performance analysis

## Performance Monitoring

1. **Prediction Accuracy**
   - Track in `match_predictions` table
   - Review accuracy trends over time
   - Monitor surface-specific performance

2. **Model Health**
   - Check feature importance plots
   - Review confusion matrices
   - Monitor AUC scores

3. **Data Quality**
   - Verify data collection completeness
   - Monitor feature generation
   - Check for missing values

## Troubleshooting

1. **Data Collection Issues**
   - Check API rate limits
   - Verify API key validity
   - Review collection logs

2. **Prediction Failures**
   - Check model file existence
   - Verify feature compatibility
   - Review prediction logs

3. **Database Issues**
   - Check connection settings
   - Verify table structures
   - Monitor disk space

## Contributing

When adding features or making changes:

1. Create feature branch
2. Update relevant documentation
3. Add/update tests
4. Submit pull request

## Future Improvements

Potential areas for enhancement:

1. Surface-specific models
2. Tournament-level adjustments
3. Player form tracking
4. Confidence scoring
5. Automated model retraining
6. Performance visualization dashboard

## Support

For issues or questions:
1. Check log files in `output/`
2. Review relevant documentation
3. Submit detailed bug reports 