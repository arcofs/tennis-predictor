# Tennis Match Prediction Pipeline (v4)

This directory contains the v4 version of the tennis match prediction pipeline.
The pipeline collects match data, generates features, trains models, and makes predictions
for upcoming tennis matches.

## Pipeline Overview

The pipeline consists of several components that run in sequence:

1. `collect_historical_matches.py`
   - Collects match data from the last 14 days
   - Stores matches in `matches` table

2. `calculate_elo.py`
   - Calculates Elo ratings for all players
   - Updates `player_elo` table

3. `collect_future_matches.py`
   - Collects upcoming match data
   - Stores in `scheduled_matches` table

4. `update_completed_matches.py`
   - Finds scheduled matches that have been completed
   - Links them to entries in `matches` table
   - Updates `is_processed` flag in `scheduled_matches`

5. `generate_historical_features.py`
   - Generates features for historical matches only
   - Stores features in `match_features` table
   - Used for model training

6. `train_model_v4.py`
   - Trains the XGBoost model using historical matches
   - Uses strict time-based train/val/test split
   - Saves model and metadata to `models` directory

7. `predict_matches.py`
   - Loads latest trained model
   - Gets unprocessed scheduled matches
   - Generates features on-the-fly using only historical data
   - Makes predictions and stores them in `match_predictions` table

8. `update_predictions.py`
   - Orchestrates the entire pipeline
   - Can be run daily via cron

## Database Tables

The pipeline uses several database tables:

- `matches`: Historical match data
- `scheduled_matches`: Upcoming match data
- `player_elo`: Player Elo ratings
- `match_features`: Features for historical matches (for training)
- `match_predictions`: Predictions for upcoming matches

## Features

The model uses the following types of features:

1. Elo rating differences
2. Recent win rates (overall and surface-specific)
3. Win/loss streaks
4. Surface-specific performance
5. Serve and return statistics

Features for historical matches (used in training) are pre-computed and stored in the database.
Features for future matches are generated on-the-fly during prediction to ensure no data leakage.

## Model Training

The model is trained using only historical matches with strict time-based separation:
- Training set: Oldest matches
- Validation set: Middle period
- Test set: Most recent matches

This ensures no future information leaks into the training process.

## Making Predictions

Predictions for upcoming matches are made by:
1. Loading the latest trained model
2. Getting unprocessed scheduled matches
3. Generating features on-the-fly using only historical data
4. Making predictions with confidence scores
5. Storing predictions in the database

## Running the Pipeline

The entire pipeline can be run using:

```bash
python predictor/v4/update_predictions.py
```

This will execute all components in sequence.

## Monitoring and Logging

Each component writes logs to `predictor/v4/output/logs/`:
- `pipeline.log`: Overall pipeline execution
- `training.log`: Model training details
- `predictions.log`: Prediction generation
- `historical_features.log`: Feature generation
- Other component-specific logs

## Model Performance

Model performance metrics are stored with each trained model in the `models` directory:
- ROC AUC
- Accuracy
- Precision/Recall
- Feature importance

## Future Improvements

Potential areas for improvement:
1. Add more features (e.g., head-to-head records)
2. Experiment with different model architectures
3. Add ensemble methods
4. Improve feature engineering
5. Add more detailed performance analysis

## Match ID Handling

Understanding match ID relationships is crucial for working with this codebase:

1. **matches table**:
   - `id`: Auto-incremented primary key generated by the database
   - `match_num`: The external API's match ID (integer)

2. **scheduled_matches table**:
   - `match_id`: The external API's match ID (stored as string)
   - `is_processed`: Flag to mark matches as completed and processed

3. **match_features table**:
   - For historical matches: `match_id` refers to `matches.id` (auto-incremented PK)
   - For future matches: `match_id` refers to `scheduled_matches.match_id` (external API ID)

4. **match_predictions table**:
   - `match_id`: References `scheduled_matches.match_id` (external API ID)

When joining tables, be careful to use the appropriate ID fields:
- To join `scheduled_matches` to `matches`: `scheduled_matches.match_id::integer = matches.match_num`
- For future matches in `match_features`: `match_features.match_id = scheduled_matches.match_id`
- For historical matches in `match_features`: `match_features.match_id = matches.id`

## Directory Structure

```
predictor/v4/
├── README.md                      # This file
├── collect_historical_matches.py  # Historical match collection script
├── calculate_elo.py              # Elo rating calculation script
├── collect_future_matches.py      # Future match collection script
├── update_completed_matches.py    # Completed match update script
├── generate_historical_features.py # Historical feature generation
├── generate_future_features.py    # Future feature generation script
├── train_model_v4.py              # Model training script
├── predict_matches.py             # Prediction script
├── update_predictions.py          # Pipeline orchestration
├── models/                        # Trained models and metadata
│   ├── model_v4_*.json           # Model files
│   ├── features_v4_*.json        # Feature lists
│   └── metrics_v4_*.json         # Performance metrics
└── output/                        # Logs and visualizations
    ├── plots/                     # Performance plots
    └── *.log                      # Log files
```

## Usage Guide

### Initial Setup

1. Ensure database connection is configured in `.env`:
```
DATABASE_URL=postgresql://user:password@host:port/dbname
TENNIS_API_KEY=your_api_key
```

2. Install required packages:
```bash
pip install -r requirements.txt
```

### Data Management

1. **Historical Data Collection**
   - Run `get_data_from_external_api.py` to populate historical match data:
   ```bash
   python external-api/get_data_from_external_api.py
   ```
   - Recommended frequency: Weekly (to capture completed match results)

2. **Elo Rating Calculation**
   - Run `calculate_elo.py` after collecting historical data to update Elo ratings:
   ```bash
   python database/calculate_elo.py
   ```
   - Ensures Elo columns in the matches table are populated

3. **Historical Feature Generation**
   - Run `generate_historical_features.py` to update features for new historical matches:
   ```bash
   python predictor/v4/generate_historical_features.py
   ```
   - Automatically included in the daily pipeline
   - Processes matches in batches to handle large volumes
   - Updates rolling window statistics for affected players
   - Supports time-based filtering via the `YEARS_TO_PROCESS` variable:
     - Set to `None` to process all matches (default)
     - Set to a number (e.g., `1`, `2`) to process only matches from the last X years
     - Useful for incremental updates or focusing on recent data

4. **Future Match Collection and Update**
   - Automatically handled by the pipeline
   - Updates daily when running `update_predictions.py`
   - Seamlessly transfers completed matches from scheduled to historical tables
   - Uses pre-calculated historical features for efficiency

### Model Training

1. **Training New Models**
   ```bash
   python predictor/v4/train_model_v4.py
   ```
   - Recommended frequency: Monthly
   - Reasons to train new model:
     - Significant new match data available
     - Performance degradation
     - Seasonal transitions

2. **Model Evaluation**
   - Check `output/plots/` for performance visualizations
   - Review metrics in `models/metrics_v4_*.json`

### Making Predictions

1. **Manual Update**
   ```bash
   python predictor/v4/update_predictions.py
   ```

2. **Automated Updates**
   Add to crontab:
   ```bash
   0 0 * * * cd /path/to/project && python predictor/v4/update_predictions.py
   ```

### Recommended Schedule

1. **Daily Operations** (via cron)
   - Run `update_predictions.py`
     - Collects historical matches (last 14 days)
     - Calculates Elo ratings
     - Collects upcoming matches
     - Updates completed matches
     - Updates historical match features
     - Generates future match features
     - Makes predictions
     - Updates accuracy

2. **Monthly Operations** (manual)
   - Train new model
   - Review performance metrics
   - Adjust features if needed

3. **Quarterly Operations** (manual)
   - Full pipeline review
   - Feature engineering assessment
   - Historical performance analysis

## Performance Monitoring

1. **Prediction Accuracy**
   - Track in `match_predictions` table
   - Review accuracy trends over time
   - Monitor surface-specific performance

2. **Model Health**
   - Check feature importance plots
   - Review confusion matrices
   - Monitor AUC scores

3. **Data Quality**
   - Verify data collection completeness
   - Monitor feature generation
   - Check for missing values

## Troubleshooting

1. **Data Collection Issues**
   - Check API rate limits
   - Verify API key validity
   - Review collection logs

2. **Prediction Failures**
   - Check model file existence
   - Verify feature compatibility
   - Review prediction logs

3. **Database Issues**
   - Check connection settings
   - Verify table structures
   - Monitor disk space

## Contributing

When adding features or making changes:

1. Create feature branch
2. Update relevant documentation
3. Add/update tests
4. Submit pull request

## Support

For issues or questions:
1. Check log files in `output/`
2. Review relevant documentation
3. Submit detailed bug reports 